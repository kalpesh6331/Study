regressor <- lm(formula = Profit ~ R.D.Spend + Administration + Marketing.Spend + State + Profit, data = dataset)
#Building the optimal model using Backword Elimination
regressor <- lm(formula = Profit ~ R.D.Spend + Administration + Marketing.Spend + State, data = dataset)
summary(regressor)
regressor <- lm(formula = Profit ~ R.D.Spend + Administration + Marketing.Spend, data = dataset)
summary(regressor)
regressor <- lm(formula = Profit ~ R.D.Spend + Marketing.Spend, data = dataset)
summary(regressor)
regressor <- lm(formula = Profit ~ R.D.Spend, data = dataset)
summary(regressor)
#Plotting graph now
library(ggplot2)
regressor <- lm(formula = Profit ~ ., data = training_set)
ggplot() +
geom_point(aes(x=training_set$R.D.Spend, y=training_set$Profit), color="Red") +
geom_line(aes(x=training_set$R.D.Spend, y=predict(regressor, newdata = training_set)), color="Blue")
setwd("C:/Kalpesh/Personal/Study/ML/Machine Learning A-Z Dataset/Part 2 - Regression/Section 6 - Polynomial Regression")
# Importing the dataset
dataset = read.csv('Position_Salaries.csv')
View(dataset)
dataset <- dataset[2:3]
# Fitting Linear Regression to the dataset
lin_reg <- lm(formula = Salary ~ Level, data = dataset)
summary(lin_reg)
# Fitting Linear Regression to the dataset
lin_reg <- lm(formula = Salary ~ ., data = dataset)
summary(lin_reg)
# Fitting Polynomial Regression to the dataset
dataset$Level2 <- dataset$Level^2
dataset$Level3 <- dataset$Level^3
poly_reg <- lm(formula = Salary ~ ., data = dataset)
summary(poly_reg)
# Visualising the Linear Regression results
# install.packages('ggplot2')
library(ggplot2)
ggplot() +
geom_point(aes(x=dataset$Level, y=dataset$Salary), color="Red") +
geom_line(aes(x=dataset$Level, y=predict(poly_reg, newdata = dataset)), color="Blue")
ggplot() +
geom_point(aes(x=dataset$Level, y=dataset$Salary), color="Red") +
geom_line(aes(x=dataset$Level, y=predict(poly_reg, newdata = dataset)), color="Blue") +
ggtitle("Level vs Salary") +
xlab("Level") +
ylab("Salary")
ggplot() +
geom_point(aes(x=dataset$Level, y=dataset$Salary), color="Red") +
geom_line(aes(x=dataset$Level, y=predict(lin_reg, newdata = dataset)), color="Blue") +
ggtitle("Level vs Salary") +
xlab("Level") +
ylab("Salary")
# Visualising the Polynomial Regression results
# install.packages('ggplot2')
ggplot() +
geom_point(aes(x=dataset$Level, y=dataset$Salary), color="Red") +
geom_line(aes(x=dataset$Level, y=predict(poly_reg, newdata = dataset)), color="Blue") +
ggtitle("Level vs Salary") +
xlab("Level") +
ylab("Salary")
# Visualising the Polynomial Regression results
# install.packages('ggplot2')
ggplot() +
geom_point(aes(x=dataset$Level, y=dataset$Salary), color="Red") +
geom_line(aes(x=dataset$Level, y=predict(poly_reg, newdata = dataset)), color="Blue") +
ggtitle("Level vs Salary (Polynomial)") +
xlab("Level") +
ylab("Salary")
dataset$Level4 <- dataset$Level^4
poly_reg <- lm(formula = Salary ~ ., data = dataset)
summary(poly_reg)
# Visualising the Polynomial Regression results
# install.packages('ggplot2')
ggplot() +
geom_point(aes(x=dataset$Level, y=dataset$Salary), color="Red") +
geom_line(aes(x=dataset$Level, y=predict(poly_reg, newdata = dataset)), color="Blue") +
ggtitle("Level vs Salary (Polynomial)") +
xlab("Level") +
ylab("Salary")
# Visualising the Polynomial Regression results
# install.packages('ggplot2')
ggplot() +
geom_point(aes(x=dataset$Level, y=dataset$Salary), color="Red") +
geom_line(aes(x=dataset$Level, y=predict(poly_reg, newdata = dataset)), color="Blue") +
ggtitle("Level vs Salary (Polynomial)") +
xlab("Level") +
ylab("Salary")
# Predicting a new result with Linear Regression
y_pred <- predict(lin_reg, newdata = data.frame(Level = 6.5))
y_pred
# Predicting a new result with Polynomial Regression
poly_pred <- predict(poly_reg, newdata = 6.5, Level2 = 6.5^2, Level3 = 6.5^3, Level4 = 6.5^4)
poly_pred
# Predicting a new result with Polynomial Regression
poly_pred <- predict(poly_reg, newdata = data.frame(Level = 6.5, Level2 = 6.5^2, Level3 = 6.5^3, Level4 = 6.5^4))
poly_pred
ggplot() +
geom_point(aes(x=dataset$Level, y=dataset$Salary), color="Red") +
geom_line(aes(x=x_grid, y=predict(poly_reg, newdata = dataset)), color="Blue") +
ggtitle("Level vs Salary (Polynomial)") +
xlab("Level") +
ylab("Salary")
x_grid = seq(min(dataset$Level), max(dataset$Level), 0.1)
ggplot() +
geom_point(aes(x=dataset$Level, y=dataset$Salary), color="Red") +
geom_line(aes(x=x_grid, y=predict(poly_reg, newdata = dataset)), color="Blue") +
ggtitle("Level vs Salary (Polynomial)") +
xlab("Level") +
ylab("Salary")
ggplot() +
geom_point(aes(x=dataset$Level, y=dataset$Salary), color="Red") +
geom_line(aes(x=x_grid, y=predict(poly_reg, newdata = data.frame(Level = x_grid))), color="Blue") +
ggtitle("Level vs Salary (Polynomial)") +
xlab("Level") +
ylab("Salary")
# Visualising the Regression Model results (for higher resolution and smoother curve)
# install.packages('ggplot2')
x_grid = seq(min(dataset$Level), max(dataset$Level), 0.1)
ggplot() +
geom_point(aes(x=dataset$Level, y=dataset$Salary), color="Red") +
geom_line(aes(x=x_grid, y=predict(poly_reg, newdata = data.frame(Level = x_grid))), color="Blue") +
ggtitle("Level vs Salary (Polynomial)") +
xlab("Level") +
ylab("Salary")
ggplot() +
geom_point(aes(x=dataset$Level, y=dataset$Salary), color="Red") +
geom_line(aes(x=x_grid, y=predict(poly_reg, newdata = data.frame(Level = x_grid))), color="Blue") +
ggtitle("Level vs Salary (Polynomial)") +
xlab("Level") +
ylab("Salary")
ggplot() +
geom_point(aes(x=dataset$Level, y=dataset$Salary), color="Red") +
geom_line(aes(x=x_grid, y=predict(poly_reg, newdata = data.frame(Levels = x_grid))), color="Blue") +
ggtitle("Level vs Salary (Polynomial)") +
xlab("Level") +
ylab("Salary")
ggplot() +
geom_point(aes(x=dataset$Level, y=dataset$Salary), color="Red") +
geom_line(aes(x=x_grid, y=predict(poly_reg, newdata = data.frame(Level = x_grid))), color="Blue") +
ggtitle("Level vs Salary (Polynomial)") +
xlab("Level") +
ylab("Salary")
# Visualising the Polynomial Regression results
# install.packages('ggplot2')
ggplot() +
geom_point(aes(x=dataset$Level, y=dataset$Salary), color="Red") +
geom_line(aes(x=dataset$Level, y=predict(poly_reg, newdata = dataset)), color="Blue") +
ggtitle("Level vs Salary (Polynomial)") +
xlab("Level") +
ylab("Salary")
setwd("C:/Kalpesh/Personal/Study/ML/Machine Learning A-Z Dataset/Part 2 - Regression/Section 7 - Support Vector Regression (SVR)")
# Fitting SVR to the dataset
install.packages('e1071')
library(e1071)
dataset = read.csv('Position_Salaries.csv')
dataset = dataset[2:3]
View(dataset)
regressor <- svm(formula = Salary ~ ., data = dataset)
summary(regressor)
regressor <- svm(formula = Salary ~ .,
data = dataset,
type = 'eps-regression')
summary(regressor)
library(ggplot2)
ggplot() +
geom_point(aes(x = dataset$Level, y = dataset$Salary),
colour = 'red') +
geom_line(aes(x = dataset$Level, y = predict(regressor, newdata = dataset)),
colour = 'blue') +
ggtitle('Truth or Bluff (SVR)') +
xlab('Level') +
ylab('Salary')
# Predicting a new result
y_pred <- predict(regressor, newdata = data.frame(Level = 6.5))
y_pred
library(ggplot2)
x_grid = seq(min(dataset$Level), max(dataset$Level), 0.1)
ggplot() +
geom_point(aes(x = dataset$Level, y = dataset$Salary),
colour = 'red') +
geom_line(aes(x = x_grid, y = predict(regressor, newdata = data.frame(Level = x_grid))),
colour = 'blue') +
ggtitle('Truth or Bluff (SVR)') +
xlab('Level') +
ylab('Salary')
setwd("C:/Kalpesh/Personal/Study/ML/Machine Learning A-Z Dataset/Part 2 - Regression/Section 8 - Decision Tree Regression")
dataset = read.csv('Position_Salaries.csv')
dataset = dataset[2:3]
View(dataset)
# Fitting Decision Tree Regression to the dataset
install.packages('rpart')
library(rpart)
regressor <- rpart(formula = Salary ~.,
data = dataset)
# Fitting Decision Tree Regression to the dataset
# install.packages('rpart')
library(rpart)
regressor <- rpart(formula = Salary ~.,
data = dataset)
# Predicting a new result with Decision Tree Regression
y_pred = predict(regressor, data.frame(Level = 6.5))
y_pred
# Visualising the Decision Tree Regression results (higher resolution)
# install.packages('ggplot2')
library(ggplot2)
x_grid = seq(min(dataset$Level), max(dataset$Level), 0.01)
ggplot() +
geom_point(aes(x = dataset$Level, y = dataset$Salary),
colour = 'red') +
geom_line(aes(x = x_grid, y = predict(regressor, newdata = data.frame(Level = x_grid))),
colour = 'blue') +
ggtitle('Truth or Bluff (Decision Tree Regression)') +
xlab('Level') +
ylab('Salary')
regressor <- rpart(formula = Salary ~.,
data = dataset,
control = rpart.control(minsplit = 1))
# Predicting a new result with Decision Tree Regression
y_pred = predict(regressor, data.frame(Level = 6.5))
y_pred
x_grid = seq(min(dataset$Level), max(dataset$Level), 0.01)
ggplot() +
geom_point(aes(x = dataset$Level, y = dataset$Salary),
colour = 'red') +
geom_line(aes(x = x_grid, y = predict(regressor, newdata = data.frame(Level = x_grid))),
colour = 'blue') +
ggtitle('Truth or Bluff (Decision Tree Regression)') +
xlab('Level') +
ylab('Salary')
regressor <- rpart(formula = Salary ~.,
data = dataset,
control = rpart.control(minsplit = 2))
# Predicting a new result with Decision Tree Regression
y_pred = predict(regressor, data.frame(Level = 6.5))
y_pred
x_grid = seq(min(dataset$Level), max(dataset$Level), 0.01)
ggplot() +
geom_point(aes(x = dataset$Level, y = dataset$Salary),
colour = 'red') +
geom_line(aes(x = x_grid, y = predict(regressor, newdata = data.frame(Level = x_grid))),
colour = 'blue') +
ggtitle('Truth or Bluff (Decision Tree Regression)') +
xlab('Level') +
ylab('Salary')
regressor <- rpart(formula = Salary ~.,
data = dataset,
control = rpart.control(minsplit = 1))
# Predicting a new result with Decision Tree Regression
y_pred = predict(regressor, data.frame(Level = 6.5))
y_pred
setwd("C:/Kalpesh/Personal/Study/ML/Machine Learning A-Z Dataset/Part 2 - Regression/Section 9 - Random Forest Regression")
# Importing the dataset
dataset = read.csv('Position_Salaries.csv')
dataset = dataset[2:3]
# Fitting Random Forest Regression to the dataset
install.packages('randomForest')
library(randomForest)
# Fitting Random Forest Regression to the dataset
# install.packages('randomForest')
library(randomForest)
set.seed(1234)
regressor <- randomForest(x = dataset[1],
y = dataset$Salary,
ntree = 10)
# Predicting a new result with Random Forest Regression
y_pred = predict(regressor, data.frame(Level = 6.5))
# Visualising the Random Forest Regression results (higher resolution)
# install.packages('ggplot2')
library(ggplot2)
x_grid = seq(min(dataset$Level), max(dataset$Level), 0.01)
ggplot() +
geom_point(aes(x = dataset$Level, y = dataset$Salary),
colour = 'red') +
geom_line(aes(x = x_grid, y = predict(regressor, newdata = data.frame(Level = x_grid))),
colour = 'blue') +
ggtitle('Truth or Bluff (Random Forest Regression)') +
xlab('Level') +
ylab('Salary')
regressor <- randomForest(x = dataset[1],
y = dataset$Salary,
ntree = 10)
# Predicting a new result with Random Forest Regression
y_pred = predict(regressor, data.frame(Level = 6.5))
regressor <- randomForest(x = dataset[1],
y = dataset$Salary,
ntree = 10)
# Predicting a new result with Random Forest Regression
y_pred = predict(regressor, data.frame(Level = 6.5))
regressor <- randomForest(x = dataset[1],
y = dataset$Salary,
ntree = 10)
# Predicting a new result with Random Forest Regression
y_pred = predict(regressor, data.frame(Level = 6.5))
regressor <- randomForest(x = dataset[1],
y = dataset$Salary,
ntree = 100)
# Predicting a new result with Random Forest Regression
y_pred = predict(regressor, data.frame(Level = 6.5))
ggplot() +
geom_point(aes(x = dataset$Level, y = dataset$Salary),
colour = 'red') +
geom_line(aes(x = x_grid, y = predict(regressor, newdata = data.frame(Level = x_grid))),
colour = 'blue') +
ggtitle('Truth or Bluff (Random Forest Regression)') +
xlab('Level') +
ylab('Salary')
regressor <- randomForest(x = dataset[1],
y = dataset$Salary,
ntree = 500)
# Predicting a new result with Random Forest Regression
y_pred = predict(regressor, data.frame(Level = 6.5))
# Visualising the Random Forest Regression results (higher resolution)
# install.packages('ggplot2')
library(ggplot2)
x_grid = seq(min(dataset$Level), max(dataset$Level), 0.01)
ggplot() +
geom_point(aes(x = dataset$Level, y = dataset$Salary),
colour = 'red') +
geom_line(aes(x = x_grid, y = predict(regressor, newdata = data.frame(Level = x_grid))),
colour = 'blue') +
ggtitle('Truth or Bluff (Random Forest Regression)') +
xlab('Level') +
ylab('Salary')
regressor <- randomForest(x = dataset[1],
y = dataset$Salary,
ntree = 5000)
# Predicting a new result with Random Forest Regression
y_pred = predict(regressor, data.frame(Level = 6.5))
# Visualising the Random Forest Regression results (higher resolution)
# install.packages('ggplot2')
library(ggplot2)
x_grid = seq(min(dataset$Level), max(dataset$Level), 0.01)
ggplot() +
geom_point(aes(x = dataset$Level, y = dataset$Salary),
colour = 'red') +
geom_line(aes(x = x_grid, y = predict(regressor, newdata = data.frame(Level = x_grid))),
colour = 'blue') +
ggtitle('Truth or Bluff (Random Forest Regression)') +
xlab('Level') +
ylab('Salary')
regressor <- randomForest(x = dataset[1],
y = dataset$Salary,
ntree = 500)
# Predicting a new result with Random Forest Regression
y_pred = predict(regressor, data.frame(Level = 6.5))
# Visualising the Random Forest Regression results (higher resolution)
# install.packages('ggplot2')
library(ggplot2)
x_grid = seq(min(dataset$Level), max(dataset$Level), 0.01)
ggplot() +
geom_point(aes(x = dataset$Level, y = dataset$Salary),
colour = 'red') +
geom_line(aes(x = x_grid, y = predict(regressor, newdata = data.frame(Level = x_grid))),
colour = 'blue') +
ggtitle('Truth or Bluff (Random Forest Regression)') +
xlab('Level') +
ylab('Salary')
regressor <- randomForest(x = dataset[1],
y = dataset$Salary,
ntree = 500)
# Predicting a new result with Random Forest Regression
y_pred = predict(regressor, data.frame(Level = 6.5))
# Visualising the Random Forest Regression results (higher resolution)
# install.packages('ggplot2')
library(ggplot2)
x_grid = seq(min(dataset$Level), max(dataset$Level), 0.01)
ggplot() +
geom_point(aes(x = dataset$Level, y = dataset$Salary),
colour = 'red') +
geom_line(aes(x = x_grid, y = predict(regressor, newdata = data.frame(Level = x_grid))),
colour = 'blue') +
ggtitle('Truth or Bluff (Random Forest Regression)') +
xlab('Level') +
ylab('Salary')
regressor <- randomForest(x = dataset[1],
y = dataset$Salary,
ntree = 500)
# Predicting a new result with Random Forest Regression
y_pred = predict(regressor, data.frame(Level = 6.5))
regressor <- randomForest(x = dataset[1],
y = dataset$Salary,
ntree = 500)
# Predicting a new result with Random Forest Regression
y_pred = predict(regressor, data.frame(Level = 6.5))
regressor <- randomForest(x = dataset[1],
y = dataset$Salary,
ntree = 500)
# Predicting a new result with Random Forest Regression
y_pred = predict(regressor, data.frame(Level = 6.5))
regressor <- randomForest(x = dataset[1],
y = dataset$Salary,
ntree = 500)
# Predicting a new result with Random Forest Regression
y_pred = predict(regressor, data.frame(Level = 6.5))
regressor <- randomForest(x = dataset[1],
y = dataset$Salary,
ntree = 500)
# Predicting a new result with Random Forest Regression
y_pred = predict(regressor, data.frame(Level = 6.5))
regressor <- randomForest(x = dataset[1],
y = dataset$Salary,
ntree = 500)
# Predicting a new result with Random Forest Regression
y_pred = predict(regressor, data.frame(Level = 6.5))
regressor <- randomForest(x = dataset[1],
y = dataset$Salary,
ntree = 500)
# Predicting a new result with Random Forest Regression
y_pred = predict(regressor, data.frame(Level = 6.5))
setwd("C:/Kalpesh/Personal/Study/ML/Machine Learning A-Z Dataset/Part 3 - Classification/Section 14 - Logistic Regression")
dataset = read.csv('Social_Network_Ads.csv')
View(dataset)
dataset = dataset[3:5]
library(caTools)
set.seed(123)
split <- sample.split(dataset$Purchased, SplitRatio = 0.75)
training_set <- subset(dataset, split == T)
test_set <- subset(dataset, split == F)
View(test_set)
View(training_set)
dataset = dataset[,3:5]
dataset = dataset[, 3:5]
dataset = dataset[3:5]
# Importing the dataset
dataset = read.csv('Social_Network_Ads.csv')
dataset = dataset[3:5]
# Splitting the dataset into the Training set and Test set
# install.packages('caTools')
library(caTools)
set.seed(123)
split <- sample.split(dataset$Purchased, SplitRatio = 0.75)
training_set <- subset(dataset, split == T)
test_set <- subset(dataset, split == F)
# Feature Scaling
training_set[, 1:2] <- scale(training_set[, 1:2])
test_set[, 1:2] <- scale(test_set[, 1:2])
# Fitting Logistic Regression to the Training set
classifier <- glm(formula = Purchased ~.,
family = binomial,
data = training_set)
View(classifier)
# Predicting the Test set results
prob_pred <- predict(classifier, type = 'response', newdata = test_set[-3])
y_pred <- ifelse(prob_pred > 0.5, 1, 0)
# Making the Confusion Matrix
cm <- table(test_set[, 3], y_pred)
cm
# Visualising the Training set results
install.packages('ElemStatLearn')
library(ElemStatLearn)
set <- training_set
library(ElemStatLearn)
set <- training_set
X1 <- seq(min(set[,1]) - 1, max(set[,1]) + 1, by = 0.01)
X2 <- seq(min(set[,2]) - 1, max(set[,2]) + 1, by = 0.01)
grid_set <- expand.grid(X1, X2)
colnames(grid_set) <- c('Age', 'EstimatedSalary')
prob_pred <- predict(classifier, type = 'response', newdata = grid_set)
y_pred <- ifelse(prob_pred > 0.5, 1, 0)
prob_pred <- predict(classifier, type = 'response', newdata = test_set[-3])
y_pred <- ifelse(prob_pred > 0.5, 1, 0)
library(ElemStatLearn)
set <- training_set
X1 <- seq(min(set[,1]) - 1, max(set[,1]) + 1, by = 0.01)
X2 <- seq(min(set[,2]) - 1, max(set[,2]) + 1, by = 0.01)
grid_set <- expand.grid(X1, X2)
colnames(grid_set) <- c('Age', 'EstimatedSalary')
prob_pred <- predict(classifier, type = 'response', newdata = grid_set)
y_grid <- ifelse(prob_pred > 0.5, 1, 0)
library(ElemStatLearn)
set <- training_set
X1 <- seq(min(set[,1]) - 1, max(set[,1]) + 1, by = 0.01)
X2 <- seq(min(set[,2]) - 1, max(set[,2]) + 1, by = 0.01)
grid_set <- expand.grid(X1, X2)
colnames(grid_set) <- c('Age', 'EstimatedSalary')
prob_pred <- predict(classifier, type = 'response', newdata = grid_set)
y_grid <- ifelse(prob_pred > 0.5, 1, 0)
plot(set[, -3],
main = 'Logistic Regression (Training Set)',
xlab = 'Age', ylab = 'Salary',
xlim = range(X1), ylim = range(X2))
contour(X1, X2, matrix(as.numeric(y_grid), length(X1), length(X2)), add = TRUE)
points(grid_set, pch = '.', col = ifelse(y_grid == 1, 'springgreen3', 'tomato'))
points(set, pch = 21, bg = ifelse(set[,3] == 1, 'green4', 'red3'))
library(ElemStatLearn)
set <- training_set
X1 <- seq(min(set[,1]) - 1, max(set[,1]) + 1, by = 0.01)
X2 <- seq(min(set[,2]) - 1, max(set[,2]) + 1, by = 0.01)
grid_set <- expand.grid(X1, X2)
colnames(grid_set) <- c('Age', 'EstimatedSalary')
prob_pred <- predict(classifier, type = 'response', newdata = grid_set)
y_grid <- ifelse(prob_pred > 0.5, 1, 0)
plot(set[, -3],
main = 'Logistic Regression (Training Set)',
xlab = 'Age', ylab = 'Salary',
xlim = range(X1), ylim = range(X2))
contour(X1, X2, matrix(as.numeric(y_grid), length(X1), length(X2)), add = TRUE)
points(grid_set, pch = '.', col = ifelse(y_grid == 1, 'springgreen3', 'tomato'))
points(set, pch = 21, bg = ifelse(set[,3] == 1, 'green4', 'red3'))
library(ElemStatLearn)
set <- test_set
X1 <- seq(min(set[,1]) - 1, max(set[,1]) + 1, by = 0.01)
X2 <- seq(min(set[,2]) - 1, max(set[,2]) + 1, by = 0.01)
grid_set <- expand.grid(X1, X2)
colnames(grid_set) <- c('Age', 'EstimatedSalary')
prob_pred <- predict(classifier, type = 'response', newdata = grid_set)
y_grid <- ifelse(prob_pred > 0.5, 1, 0)
plot(set[, -3],
main = 'Logistic Regression (Test Set)',
xlab = 'Age', ylab = 'Salary',
xlim = range(X1), ylim = range(X2))
contour(X1, X2, matrix(as.numeric(y_grid), length(X1), length(X2)), add = TRUE)
points(grid_set, pch = '.', col = ifelse(y_grid == 1, 'springgreen3', 'tomato'))
points(set, pch = 21, bg = ifelse(set[,3] == 1, 'green4', 'red3'))
